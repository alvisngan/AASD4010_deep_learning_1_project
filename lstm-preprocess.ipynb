{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbdd6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae822b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_directory(directory_path, sample_rate=22050, segment_duration=3, n_mfcc=40):\n",
    "    \"\"\"\n",
    "    Concatenates audio files, extracts fixed-length segments, calculates MFCCs, and saves them.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing .wav files.\n",
    "        sample_rate (int): The target sample rate for all audio files.\n",
    "        segment_duration (int): Duration in seconds for each audio segment.\n",
    "        n_mfcc (int): Number of MFCC coefficients to extract.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 3D NumPy array containing all extracted MFCC samples.\n",
    "                    Shape will be (num_samples, n_mfcc, num_frames).\n",
    "    \"\"\"\n",
    "    full_audio = []\n",
    "    \n",
    "    # 1. Load and concatenate all audio files\n",
    "    print(\"Loading and concatenating audio files...\")\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # librosa.load resamples the audio to the target_sr by default\n",
    "            y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "            full_audio.append(y)\n",
    "    \n",
    "    # Concatenate all audio segments into a single array\n",
    "    concatenated_audio = np.concatenate(full_audio)\n",
    "    \n",
    "    # Calculate the number of samples per segment\n",
    "    segment_length = segment_duration * sample_rate\n",
    "    \n",
    "    mfcc_samples = []\n",
    "    \n",
    "    # 2. Extract small samples and calculate MFCCs\n",
    "    print(\"Extracting segments and calculating MFCCs...\")\n",
    "    for i in range(0, len(concatenated_audio), segment_length):\n",
    "        # Take a segment of the audio\n",
    "        segment = concatenated_audio[i:i + segment_length]\n",
    "        \n",
    "        # Skip incomplete segments at the end\n",
    "        if len(segment) < segment_length:\n",
    "            continue\n",
    "        \n",
    "        # Calculate MFCCs for the segment\n",
    "        mfccs = librosa.feature.mfcc(y=segment, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # Append the MFCCs to our list\n",
    "        mfcc_samples.append(mfccs)\n",
    "        \n",
    "    print(f\"Total MFCC samples created: {len(mfcc_samples)}\")\n",
    "    \n",
    "    # Convert list of 2D arrays to a single 3D NumPy array\n",
    "    return np.array(mfcc_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63a3e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6... Loading and concatenating audio files...\n",
      "Extracting segments and calculating MFCCs...\n",
      "Total MFCC samples created: 814\n",
      "Shape of the final training data: (814, 40, 130)\n",
      "10... Loading and concatenating audio files...\n",
      "Extracting segments and calculating MFCCs...\n",
      "Total MFCC samples created: 172\n",
      "Shape of the final training data: (172, 40, 130)\n",
      "8... Loading and concatenating audio files...\n",
      "Extracting segments and calculating MFCCs...\n",
      "Total MFCC samples created: 350\n",
      "Shape of the final training data: (350, 40, 130)\n",
      "4... Loading and concatenating audio files...\n",
      "Extracting segments and calculating MFCCs...\n",
      "Total MFCC samples created: 274\n",
      "Shape of the final training data: (274, 40, 130)\n",
      "12... Loading and concatenating audio files...\n",
      "Extracting segments and calculating MFCCs...\n",
      "Total MFCC samples created: 230\n",
      "Shape of the final training data: (230, 40, 130)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your directory of .wav files\n",
    "audio_directory = 'data/lstm_data'\n",
    "\n",
    "#print each subdirectory in audio_directory unless it has a \".\"\n",
    "for subdir in os.listdir(audio_directory):\n",
    "    if '.' not in subdir:\n",
    "        print(subdir + \"... \", end='')\n",
    "\n",
    "        # Process the audio and get the training samples\n",
    "        training_data = process_audio_directory(audio_directory + '/' + subdir)\n",
    "\n",
    "        # The shape of your training data is now:\n",
    "        # (number_of_segments, n_mfcc, number_of_frames_per_segment)\n",
    "        # This is the ideal input shape for an LSTM network.\n",
    "        print(f\"Shape of the final training data: {training_data.shape}\")\n",
    "\n",
    "        # You can save this data for later use\n",
    "        np.save(f'data/lstm_data/{subdir}_data.npy', training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c41ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-312 (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
