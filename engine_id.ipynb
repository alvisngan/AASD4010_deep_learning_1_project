{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91cb3a5",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "- [Project Configuration](engine_id.ipynb#project-configuration)\n",
    "- [Reproducability](engine_id.ipynb#reproducibility--device)\n",
    "- [Dataset](engine_id.ipynb#dataset)\n",
    "- [Pre-processing](engine_id.ipynb#pre-processing)\n",
    "- [Convolutional Neural Network](engine_id.ipynb#convolutional-neural-network)\n",
    "- [Optimizer and Scheduler](engine_id.ipynb#optimizer--scheduler)\n",
    "- [Combine Everything](engine_id.ipynb#combine-everything)\n",
    "- [Run](engine_id.ipynb#run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f50ca1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "# Our own custom signal processing library\n",
    "from signal_processing import process_audio_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae6ec5",
   "metadata": {},
   "source": [
    "## Project Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf1e6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Top-level configuration for the training run.\n",
    "\n",
    "    Attributes:\n",
    "        data_dir: Root directory containing class subfolders of wav files.\n",
    "\n",
    "        use_cepstrum: If True, use the cepstrum dataset; otherwise spectrum.\n",
    "\n",
    "        batch_size_train: Batch size for training.\n",
    "\n",
    "        batch_size_val: Batch size for evaluation.\n",
    "\n",
    "        test_size: Fraction of data reserved for validation (0 < test_size < 1).\n",
    "\n",
    "        seed: Random seed used across numpy/torch/random.\n",
    "\n",
    "        lr: Initial learning rate for Adam.\n",
    "\n",
    "        weight_decay: L2 regularization coefficient.\n",
    "\n",
    "        epochs: Number of training epochs.\n",
    "\n",
    "        num_workers: DataLoader workers; 0 is often fastest on small CPU jobs.\n",
    "        \n",
    "        pin_memory: Set True when training on CUDA; False on pure CPU is fine.\n",
    "    \"\"\"\n",
    "    data_dir: str = \"data_dir\"\n",
    "    use_cepstrum: bool = False\n",
    "    batch_size_train: int = 32\n",
    "    batch_size_val: int = 128\n",
    "    test_size: float = 0.2\n",
    "    seed: int = 42\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    epochs: int = 40\n",
    "    num_workers: int = 0\n",
    "    pin_memory: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66802b44",
   "metadata": {},
   "source": [
    "## Reproducibility & device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b156c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"Set random seeds for reproducible experiments.\n",
    "\n",
    "    Args:\n",
    "        seed: Integer seed applied to Python, NumPy, and PyTorch RNGs.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec0815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"Select an available computation device.\n",
    "\n",
    "    Returns:\n",
    "        A `torch.device` set to CUDA if available; otherwise CPU.\n",
    "    \"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bebeac",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6f6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for finding wave files in the directory\n",
    "\n",
    "def is_wav(p: Path) -> bool:\n",
    "    return p.suffix.lower() == \".wav\"\n",
    "\n",
    "def _discover_wavs(root) -> List[Tuple[Path, int]]:\n",
    "    \"\"\"\n",
    "    Discover .wav files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        root (path or str): The root directory of the categorized audio files\n",
    "                            The file structure should look like this:\n",
    "                                root/\n",
    "                                    4/\n",
    "                                        *.wav\n",
    "                                    6/\n",
    "                                        *.wav\n",
    "                                    8/\n",
    "                                        *.wav\n",
    "                                    ....\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        items (List[Tuple[Path, int]]): A list of tuples of .wav file path\n",
    "                                        and the number of cylinders\n",
    "\n",
    "    \"\"\"\n",
    "    root = Path(root)\n",
    "    items = []\n",
    "    for cls_dir in sorted(root.iterdir()):\n",
    "        if not cls_dir.is_dir():\n",
    "            continue\n",
    "        try:\n",
    "            cylinders = int(cls_dir.name)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        for wav in sorted(cls_dir.rglob(\"*.wav\")):\n",
    "            if is_wav(wav):\n",
    "                items.append((wav, cylinders))\n",
    "    if not items:\n",
    "        raise FileNotFoundError(f\"No wavs found under {root}\")\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b19612d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset Core Object\n",
    "\n",
    "class _BaseEngineAudioDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Base Dataset that calls process_audio_wav and returns either spectrum or \n",
    "    cepstrum.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        root_dir : str | Path\n",
    "            Root containing class folders (e.g., 4,6,8).\n",
    "            The file structure should look like this:\n",
    "                root/\n",
    "                    4/\n",
    "                        *.wav\n",
    "                    6/\n",
    "                        *.wav\n",
    "                    8/\n",
    "                        *.wav\n",
    "                    ....\n",
    "        mode : str\n",
    "            'spectrum' or 'cepstrum' (which feature to return as X).\n",
    "\n",
    "        process_kwargs : dict\n",
    "            Keyword args forwarded to process_audio_wav.\n",
    "            \n",
    "        to_channel_first : bool\n",
    "            If True, X is returned as (1, L) for easy 1D-CNN use. \n",
    "            If False, shape is (L,).\n",
    "\n",
    "        transform : Optional[Callable[[torch.Tensor], torch.Tensor]]\n",
    "            Optional transform applied to X (after to_channel_first).\n",
    "\n",
    "        target_transform : Optional[Callable[[int], int]]\n",
    "            Transform applied to y_class (the 0..C-1 class index).\n",
    "\n",
    "        return_cylinders_as_target : bool\n",
    "            If True, y is the raw cylinder count (e.g., 4,6,8). \n",
    "            NOTE: CrossEntropyLoss\n",
    "            expects targets in 0..C-1; if you set this True, \n",
    "            use an appropriate loss.\n",
    "\n",
    "        cache_in_memory : bool\n",
    "            If True, keep processed features in RAM to speed up subsequent \n",
    "            epochs.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: Union[str, Path],\n",
    "        mode: str,\n",
    "        process_kwargs: Optional[dict] = None,\n",
    "        to_channel_first: bool = True,\n",
    "        transform: Optional[Callable[[torch.Tensor], torch.Tensor]] = None,\n",
    "        target_transform: Optional[Callable[[int], int]] = None,\n",
    "        return_cylinders_as_target: bool = False,\n",
    "        cache_in_memory: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        assert mode in (\"spectrum\", \"cepstrum\")\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.mode = mode\n",
    "        self.process_kwargs = process_kwargs or {}\n",
    "        self.to_channel_first = to_channel_first\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.return_cylinders_as_target = return_cylinders_as_target\n",
    "        self.cache_in_memory = cache_in_memory\n",
    "\n",
    "        # Discover files and raw cylinder labels\n",
    "        pairs = _discover_wavs(self.root_dir)  # [(path, cylinders), ...]\n",
    "        self.wavs: List[Path] = [p for p, _ in pairs]\n",
    "        cyls: List[int] = [c for _, c in pairs]\n",
    "\n",
    "        # Make stable mapping: class_index <-> cylinders\n",
    "        uniq = sorted(set(cyls))               # e.g., [4, 6, 8]\n",
    "        self.class_to_cylinders: Dict[int, int] = {i: v for i, v in enumerate(uniq)}\n",
    "        self.cylinders_to_class: Dict[int, int] = {v: i for i, v in self.class_to_cylinders.items()}\n",
    "\n",
    "        self.y_class: List[int] = [self.cylinders_to_class[c] for c in cyls]  # 0..C-1 per sample\n",
    "        self.y_cylinders: List[int] = cyls                                   # e.g., 4/6/8 per sample\n",
    "\n",
    "        # Optional in-RAM cache: index -> (torch.FloatTensor X, int y)\n",
    "        self._cache: Dict[int, Tuple[torch.Tensor, int]] = {}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.wavs)\n",
    "\n",
    "    def _compute_features(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        # Call user's processing function\n",
    "        p = str(self.wavs[idx])\n",
    "        spectrum_power, cepstrum_mag, spectrum_order, cepstrum_qref = process_audio_wav(\n",
    "            p, **self.process_kwargs\n",
    "        )\n",
    "        # Select feature by mode\n",
    "        if self.mode == \"spectrum\":\n",
    "            x_np = np.asarray(spectrum_power, dtype=np.float32)  # shape (L_spec,)\n",
    "        else:  # 'cepstrum'\n",
    "            x_np = np.asarray(cepstrum_mag, dtype=np.float32)    # shape (L_ceps,)\n",
    "\n",
    "        x = torch.from_numpy(x_np)  # (L,)\n",
    "        if self.to_channel_first:\n",
    "            x = x.unsqueeze(0)       # (1, L) for Conv1d\n",
    "\n",
    "        return x, self.y_class[idx]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        # Serve from cache if enabled\n",
    "        if self.cache_in_memory and idx in self._cache:\n",
    "            x, y_class = self._cache[idx]\n",
    "        else:\n",
    "            x, y_class = self._compute_features(idx)\n",
    "            if self.cache_in_memory:\n",
    "                self._cache[idx] = (x, y_class)\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        if self.return_cylinders_as_target:\n",
    "            y = self.y_cylinders[idx]  # e.g., 4/6/8\n",
    "        else:\n",
    "            y = y_class                # 0..C-1\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            y = self.target_transform(y)\n",
    "\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d000de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Spectrum and Cepstrum classes\n",
    "\n",
    "class EngineSpectrumDataset(_BaseEngineAudioDataset):\n",
    "    def __init__(self, root_dir, **kwargs):\n",
    "        super().__init__(root_dir, mode=\"spectrum\", **kwargs)\n",
    "\n",
    "class EngineCepstrumDataset(_BaseEngineAudioDataset):\n",
    "    def __init__(self, root_dir, **kwargs):\n",
    "        super().__init__(root_dir, mode=\"cepstrum\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4b8de",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "Building dataset, spliting test samples, balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a1a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zscore_transform(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Apply per-sample z-score normalization to a (C, L) tensor.\n",
    "\n",
    "    z = (x - mean) / std, computed across the last dimension (time/frequency).\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape (C, L). Typically C=1 for 1D Conv input.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (C, L) with normalized values.\n",
    "    \"\"\"\n",
    "    m = x.mean(dim=-1, keepdim=True)\n",
    "    s = x.std(dim=-1, keepdim=True) + 1e-8\n",
    "    return (x - m) / s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52c2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(cfg: Config):\n",
    "    \"\"\"Create the spectrum or cepstrum dataset with a z-score transform.\n",
    "\n",
    "    Args:\n",
    "        cfg: Run configuration.\n",
    "\n",
    "    Returns:\n",
    "        A PyTorch Dataset that yields tuples (X, y), where:\n",
    "          - X: Float tensor of shape (1, L) (channel-first)\n",
    "          - y: Integer class index in [0, num_classes).\n",
    "    \"\"\"\n",
    "    DSClass = EngineCepstrumDataset if cfg.use_cepstrum else EngineSpectrumDataset\n",
    "    ds = DSClass(\n",
    "        cfg.data_dir,\n",
    "        process_kwargs=dict(\n",
    "            nperseg=4096, noverlap=256,\n",
    "            num_peaks=3,\n",
    "            num_orders=8, bins_per_interval=30,\n",
    "            normalize_at_1x=False,\n",
    "            to_decibel=True\n",
    "        ),\n",
    "        to_channel_first=True,      # -> (1, L) for Conv1d\n",
    "        transform=zscore_transform, # normalize each sample consistently\n",
    "        return_cylinders_as_target=False,\n",
    "        cache_in_memory=True,\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e5e27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split_indices(y: np.ndarray, test_size: float, seed: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Create stratified train/val indices to preserve class ratios.\n",
    "\n",
    "    Args:\n",
    "        y: Array of class indices for the full dataset, shape (N,).\n",
    "        test_size: Fraction of samples assigned to validation.\n",
    "        seed: Random seed for the split.\n",
    "\n",
    "    Returns:\n",
    "        (train_idx, val_idx): Two numpy arrays of indices into the dataset.\n",
    "    \"\"\"\n",
    "    idx_all = np.arange(len(y))\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "    train_idx, val_idx = next(sss.split(idx_all, y))\n",
    "    return train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423e6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_balanced_loaders(\n",
    "    ds,\n",
    "    train_idx: np.ndarray,\n",
    "    val_idx: np.ndarray,\n",
    "    cfg: Config\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"Create training and validation DataLoaders with a balanced train sampler.\n",
    "\n",
    "    The training loader uses a WeightedRandomSampler to approximately balance\n",
    "    the class distribution in each epoch. The validation loader is deterministic.\n",
    "\n",
    "    Args:\n",
    "        ds: Dataset instance built by `build_dataset`.\n",
    "        train_idx: Numpy array of training indices.\n",
    "        val_idx: Numpy array of validation indices.\n",
    "        cfg: Run configuration.\n",
    "\n",
    "    Returns:\n",
    "        (train_loader, val_loader): Two DataLoader objects.\n",
    "    \"\"\"\n",
    "    train_set = Subset(ds, train_idx)\n",
    "    val_set   = Subset(ds, val_idx)\n",
    "\n",
    "    # Build per-sample weights (inverse class frequency on TRAIN)\n",
    "    y_train = np.array([ds.y_class[i] for i in train_idx])\n",
    "    num_classes = len(ds.class_to_cylinders)\n",
    "    class_counts = np.bincount(y_train, minlength=num_classes).astype(np.float64)\n",
    "    class_weights = 1.0 / np.maximum(class_counts, 1.0)\n",
    "    sample_weights = class_weights[y_train]\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.from_numpy(sample_weights).double(),\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=cfg.batch_size_train,\n",
    "        sampler=sampler,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=cfg.pin_memory\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=cfg.batch_size_val,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=cfg.pin_memory\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b498c78",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eafedab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN1D(nn.Module):\n",
    "    \"\"\"A minimal 1D CNN classifier for fixed-length 1D features.\n",
    "\n",
    "    Architecture:\n",
    "        Conv1d(1→16, k=7, pad=3) + ReLU + MaxPool(2)\n",
    "        Conv1d(16→32, k=5, pad=2) + ReLU + MaxPool(2)\n",
    "        Conv1d(32→64, k=3, pad=1) + ReLU\n",
    "        AdaptiveAvgPool1d(1) → Flatten → Linear(64→num_classes)\n",
    "\n",
    "    Input:\n",
    "        (N, 1, L) float32\n",
    "\n",
    "    Output:\n",
    "        (N, num_classes) logits (use CrossEntropyLoss)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"Initialize layers.\n",
    "\n",
    "        Args:\n",
    "            num_classes: Number of target classes.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=7, padding=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (N, 1, L).\n",
    "\n",
    "        Returns:\n",
    "            Logits tensor of shape (N, num_classes).\n",
    "        \"\"\"\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df68d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes: int, device: torch.device) -> nn.Module:\n",
    "    \"\"\"Construct and move the model to a device.\n",
    "\n",
    "    Args:\n",
    "        num_classes: Number of classes for the final classifier.\n",
    "        device: torch.device (CPU or CUDA).\n",
    "\n",
    "    Returns:\n",
    "        A model instance on the specified device.\n",
    "    \"\"\"\n",
    "    model = SimpleCNN1D(num_classes=num_classes).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f71b04",
   "metadata": {},
   "source": [
    "## Optimizer / Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da2fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_optimizer(model: nn.Module, cfg: Config) -> optim.Optimizer:\n",
    "    \"\"\"Create an Adam optimizer for the model parameters.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network to optimize.\n",
    "        cfg: Run configuration with lr and weight_decay.\n",
    "\n",
    "    Returns:\n",
    "        A configured torch.optim.Optimizer instance.\n",
    "    \"\"\"\n",
    "    return optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "\n",
    "def build_scheduler(optimizer: optim.Optimizer):\n",
    "    \"\"\"Build a ReduceLROnPlateau scheduler driven by validation accuracy.\n",
    "\n",
    "    Args:\n",
    "        optimizer: The optimizer to schedule.\n",
    "\n",
    "    Returns:\n",
    "        A torch.optim.lr_scheduler.ReduceLROnPlateau instance.\n",
    "    \"\"\"\n",
    "    return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"max\", factor=0.5, patience=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5883d",
   "metadata": {},
   "source": [
    "## Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0c9a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Train the model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: Neural network in training mode.\n",
    "        loader: DataLoader providing (X, y) mini-batches.\n",
    "        optimizer: Optimizer for parameter updates.\n",
    "        criterion: Loss function (e.g., nn.CrossEntropyLoss()).\n",
    "        device: torch.device to run the computation on.\n",
    "\n",
    "    Returns:\n",
    "        Tuple (avg_loss, avg_accuracy) over the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total, correct, running = 0, 0, 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item() * xb.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "    return running / max(total, 1), correct / max(total, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d16198",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Evaluate the model on a validation/test loader.\n",
    "\n",
    "    Args:\n",
    "        model: Neural network in eval mode.\n",
    "        loader: DataLoader providing (X, y) mini-batches.\n",
    "        criterion: Loss function (e.g., nn.CrossEntropyLoss()).\n",
    "        device: torch.device to run the computation on.\n",
    "\n",
    "    Returns:\n",
    "        Tuple (avg_loss, avg_accuracy, y_true, y_pred):\n",
    "            - avg_loss: Mean loss across the dataset.\n",
    "            - avg_accuracy: Fraction correct.\n",
    "            - y_true: Numpy array of ground-truth class indices.\n",
    "            - y_pred: Numpy array of predicted class indices.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total, correct, running = 0, 0, 0.0\n",
    "    all_pred, all_true = [], []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        running += loss.item() * xb.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "        all_pred.append(pred.cpu().numpy())\n",
    "        all_true.append(yb.cpu().numpy())\n",
    "\n",
    "    y_pred = np.concatenate(all_pred) if all_pred else np.array([])\n",
    "    y_true = np.concatenate(all_true) if all_true else np.array([])\n",
    "    return running / max(total, 1), correct / max(total, 1), y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a863e",
   "metadata": {},
   "source": [
    "## Combine Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd3253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(cfg: Config) -> None:\n",
    "    \"\"\"End-to-end training run: dataset, loaders, model, training, metrics.\n",
    "\n",
    "    This function prints per-epoch train/val loss/accuracy and a final\n",
    "    confusion matrix + classification report.\n",
    "\n",
    "    Args:\n",
    "        cfg: Configuration values that drive the whole pipeline.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If the dataset has fewer than 2 classes.\n",
    "    \"\"\"\n",
    "    set_seed(cfg.seed)\n",
    "    device = get_device()\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Dataset\n",
    "    ds = build_dataset(cfg)\n",
    "    num_classes = len(ds.class_to_cylinders)\n",
    "    if num_classes < 2:\n",
    "        raise RuntimeError(\"Need at least 2 classes for classification.\")\n",
    "\n",
    "    print(\"Classes (index -> cylinders):\", ds.class_to_cylinders)\n",
    "\n",
    "    # Stratified split\n",
    "    y_all = np.array(ds.y_class)\n",
    "    train_idx, val_idx = stratified_split_indices(y_all, cfg.test_size, cfg.seed)\n",
    "    print(\"FULL:\", Counter(ds.y_class))\n",
    "    print(\"TRAIN:\", Counter(ds.y_class[i] for i in train_idx))\n",
    "    print(\"VAL:\", Counter(ds.y_class[i] for i in val_idx))\n",
    "\n",
    "    # Loaders\n",
    "    train_loader, val_loader = make_balanced_loaders(ds, train_idx, val_idx, cfg)\n",
    "\n",
    "    # Model / Optim / Sched / Loss\n",
    "    model = build_model(num_classes=num_classes, device=device)\n",
    "    print(model)\n",
    "    print(\"Trainable params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "    optimizer = build_optimizer(model, cfg)\n",
    "    scheduler = build_scheduler(optimizer)\n",
    "    criterion = nn.CrossEntropyLoss()  # unweighted (balanced sampler already compensates)\n",
    "\n",
    "    # Train\n",
    "    best_val_acc = 0.0\n",
    "    for ep in range(1, cfg.epochs + 1):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        va_loss, va_acc, y_true, y_pred = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {ep:02d} | train {tr_loss:.4f}/{tr_acc*100:5.1f}% | \"\n",
    "              f\"val {va_loss:.4f}/{va_acc*100:5.1f}%\")\n",
    "        scheduler.step(va_acc)\n",
    "        best_val_acc = max(best_val_acc, va_acc)\n",
    "\n",
    "    print(\"\\nBest val accuracy: {:.2f}%\".format(best_val_acc * 100))\n",
    "\n",
    "    # Final metrics\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\\n\", cm)\n",
    "\n",
    "    idx2cyl = ds.class_to_cylinders\n",
    "    print(\"\\nClass indices -> cylinders:\", idx2cyl)\n",
    "\n",
    "    print(\"\\nClassification report (by class index):\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "    # Optional: pretty print confusion matrix with cylinder labels\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        headers = [f\"pred_{idx2cyl[i]}\" for i in range(num_classes)]\n",
    "        index   = [f\"true_{idx2cyl[i]}\" for i in range(num_classes)]\n",
    "        cm_df = pd.DataFrame(cm, index=index, columns=headers)\n",
    "        print(\"\\nConfusion Matrix (labeled):\")\n",
    "        print(cm_df.to_string())\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b91fd",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58fee375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Classes (index -> cylinders): {0: 4, 1: 6}\n",
      "FULL: Counter({0: 33, 1: 16})\n",
      "TRAIN: Counter({0: 26, 1: 13})\n",
      "VAL: Counter({0: 7, 1: 3})\n",
      "SimpleCNN1D(\n",
      "  (net): Sequential(\n",
      "    (0): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): AdaptiveAvgPool1d(output_size=1)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Trainable params: 9058\n",
      "Epoch 01 | train 0.6990/ 48.7% | val 0.7141/ 30.0%\n",
      "Epoch 02 | train 0.6907/ 53.8% | val 0.7102/ 30.0%\n",
      "Epoch 03 | train 0.6934/ 48.7% | val 0.7017/ 30.0%\n",
      "Epoch 04 | train 0.6903/ 53.8% | val 0.6942/ 40.0%\n",
      "Epoch 05 | train 0.6909/ 51.3% | val 0.6890/ 60.0%\n",
      "Epoch 06 | train 0.6896/ 69.2% | val 0.6843/ 90.0%\n",
      "Epoch 07 | train 0.6873/ 76.9% | val 0.6776/ 70.0%\n",
      "Epoch 08 | train 0.6967/ 28.2% | val 0.6776/ 70.0%\n",
      "Epoch 09 | train 0.6889/ 48.7% | val 0.6800/ 80.0%\n",
      "Epoch 10 | train 0.6909/ 61.5% | val 0.6843/ 60.0%\n",
      "Epoch 11 | train 0.6818/ 76.9% | val 0.6864/ 50.0%\n",
      "Epoch 12 | train 0.6823/ 76.9% | val 0.6871/ 50.0%\n",
      "Epoch 13 | train 0.6835/ 64.1% | val 0.6863/ 60.0%\n",
      "Epoch 14 | train 0.6849/ 71.8% | val 0.6837/ 50.0%\n",
      "Epoch 15 | train 0.6846/ 59.0% | val 0.6806/ 60.0%\n",
      "Epoch 16 | train 0.6841/ 59.0% | val 0.6776/ 80.0%\n",
      "Epoch 17 | train 0.6829/ 74.4% | val 0.6760/ 80.0%\n",
      "Epoch 18 | train 0.6790/ 87.2% | val 0.6753/ 80.0%\n",
      "Epoch 19 | train 0.6773/ 76.9% | val 0.6748/ 80.0%\n",
      "Epoch 20 | train 0.6784/ 84.6% | val 0.6743/ 80.0%\n",
      "Epoch 21 | train 0.6831/ 71.8% | val 0.6737/ 80.0%\n",
      "Epoch 22 | train 0.6774/ 82.1% | val 0.6724/ 80.0%\n",
      "Epoch 23 | train 0.6775/ 87.2% | val 0.6719/ 80.0%\n",
      "Epoch 24 | train 0.6775/ 76.9% | val 0.6716/ 80.0%\n",
      "Epoch 25 | train 0.6777/ 84.6% | val 0.6713/ 80.0%\n",
      "Epoch 26 | train 0.6782/ 79.5% | val 0.6712/ 80.0%\n",
      "Epoch 27 | train 0.6772/ 82.1% | val 0.6711/ 80.0%\n",
      "Epoch 28 | train 0.6723/ 92.3% | val 0.6709/ 80.0%\n",
      "Epoch 29 | train 0.6824/ 74.4% | val 0.6708/ 80.0%\n",
      "Epoch 30 | train 0.6732/ 87.2% | val 0.6706/ 80.0%\n",
      "Epoch 31 | train 0.6804/ 71.8% | val 0.6706/ 80.0%\n",
      "Epoch 32 | train 0.6834/ 71.8% | val 0.6705/ 80.0%\n",
      "Epoch 33 | train 0.6787/ 79.5% | val 0.6704/ 80.0%\n",
      "Epoch 34 | train 0.6803/ 82.1% | val 0.6703/ 80.0%\n",
      "Epoch 35 | train 0.6784/ 76.9% | val 0.6702/ 80.0%\n",
      "Epoch 36 | train 0.6749/ 74.4% | val 0.6702/ 80.0%\n",
      "Epoch 37 | train 0.6775/ 76.9% | val 0.6701/ 80.0%\n",
      "Epoch 38 | train 0.6786/ 87.2% | val 0.6701/ 80.0%\n",
      "Epoch 39 | train 0.6778/ 84.6% | val 0.6701/ 80.0%\n",
      "Epoch 40 | train 0.6745/ 87.2% | val 0.6700/ 80.0%\n",
      "\n",
      "Best val accuracy: 90.00%\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      " [[6 1]\n",
      " [1 2]]\n",
      "\n",
      "Class indices -> cylinders: {0: 4, 1: 6}\n",
      "\n",
      "Classification report (by class index):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.8571    0.8571         7\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.8000        10\n",
      "   macro avg     0.7619    0.7619    0.7619        10\n",
      "weighted avg     0.8000    0.8000    0.8000        10\n",
      "\n",
      "\n",
      "Confusion Matrix (labeled):\n",
      "        pred_4  pred_6\n",
      "true_4       6       1\n",
      "true_6       1       2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Entry point for running the training with default (editable) config.\n",
    "\n",
    "    Edits you commonly make:\n",
    "        - Config.data_dir: set to your dataset root\n",
    "        - Config.use_cepstrum: switch to cepstrum features\n",
    "        - Config.epochs / lr: tweak training length and learning rate\n",
    "    \"\"\"\n",
    "    cfg = Config(\n",
    "        data_dir=\"../audio_clips/clips\",   # <-- set your folder here\n",
    "        use_cepstrum=False,    # True for cepstrum dataset\n",
    "        epochs=40,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        batch_size_train=32,\n",
    "        batch_size_val=128,\n",
    "        test_size=0.2,\n",
    "        seed=42,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    run_training(cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e77e75d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
